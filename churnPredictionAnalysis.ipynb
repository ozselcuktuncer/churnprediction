{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provided Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign_descDF = pd.read_csv(\"campaign_desc.csv\")\n",
    "campaign_tableDF = pd.read_csv(\"campaign_table.csv\")\n",
    "productDF = pd.read_csv(\"product.csv\")\n",
    "coupon_redemptDf = pd.read_csv(\"coupon_redempt.csv\")\n",
    "transaction_data = pd.read_csv(\"transaction_data.csv\")\n",
    "causal_dataDF = pd.read_csv(\"causal_data.csv\")\n",
    "couponDF = pd.read_csv(\"coupon.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 'duration'\n",
    "end_day = 'END_DAY'\n",
    "start_day = 'START_DAY'\n",
    "description = 'DESCRIPTION'\n",
    "campaign = 'CAMPAIGN'\n",
    "customer_id = 'household_key'\n",
    "basket_id = 'BASKET_ID'\n",
    "day = 'DAY'\n",
    "sales_value = 'SALES_VALUE'\n",
    "product_id = 'PRODUCT_ID'\n",
    "department = 'DEPARTMENT'\n",
    "brand = 'BRAND'\n",
    "store_id = 'STORE_ID'\n",
    "coupon_match = 'COUPON_MATCH_DISC'\n",
    "label = 'label'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def labelling(transaction_data):\n",
    "    \"\"\"Labelling customers who will churn as 1 and who will not churn as 0.\n",
    "    customers who exceeded their avarage purchase period was labelled as churned.\n",
    "    \"\"\"\n",
    "    \n",
    "    #lambda function to calculate average purchase time period for each customer.\n",
    "    avarage_period = lambda x: (x.max() - x.min()) / (x.count() - 1)\n",
    "    #lambda function to calculate number of days passed since the customer last purchase.\n",
    "    last_purchase_days = lambda x: 711 - x.max()\n",
    "\n",
    "    #Selecting household and days per transaction\n",
    "    house_purchaseDF = transaction_data.groupby([customer_id, basket_id])[day].min().reset_index()\n",
    "    \n",
    "    periodDF = house_purchaseDF.groupby([customer_id]).agg(\n",
    "        customer_period = pd.NamedAgg(column= day, aggfunc = avarage_period)).reset_index()\n",
    "    \n",
    "    last_visitDF =house_purchaseDF.groupby(customer_id).agg(\n",
    "        last_purchase = pd.NamedAgg(column = day, aggfunc = last_purchase_days)).reset_index()\n",
    "\n",
    "    #Labelling customers if the number of days since last purchase is greater than customers avarage period.\n",
    "    labelDF = pd.merge(periodDF,last_visitDF,on = customer_id, how = 'inner')\n",
    "    labelDF[label] = np.where(labelDF['last_purchase'] >= labelDF['customer_period'],1,0)\n",
    "    labelDF.drop(['customer_period','last_purchase'],axis = 1, inplace = True)\n",
    "    \n",
    "    return labelDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Customer features to be used in predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_proccessing_user(transaction_data,\n",
    "                          product_data,\n",
    "                          coupon_redempt):\n",
    "    \"\"\"Computing customers features with transaction and product data.\n",
    "    \"\"\"\n",
    "    \n",
    "    #lambda functions to be used in aggregations.\n",
    "    most_purchased_function = lambda column: column.value_counts().index[0]\n",
    "    count_non_zero = lambda column: column.ne(0).sum()\n",
    "    \n",
    "    #enriching transaction data with product information\n",
    "    transaction_info = pd.merge(transaction_data,\n",
    "                                productDF[[product_id,department,brand]],\n",
    "                                how='left',\n",
    "                                on=[product_id])\n",
    "    \n",
    "    #Average basket information of customers.\n",
    "    avg_customer_basket = transaction_info.groupby([customer_id,basket_id]).agg(\n",
    "        avg_customer_basket = (sales_value, 'mean'),\n",
    "        distinct_items_basket = (product_id,'nunique'),\n",
    "        items_in_basket = (product_id,'count')).groupby(level=0).agg(avg_basket_value = ('avg_customer_basket','mean'),\n",
    "                                                                     avg_distinct_items_basket = ('distinct_items_basket','mean'),\n",
    "                                                                     avg_items_in_basket = ('items_in_basket','mean')).reset_index()\n",
    "    \n",
    "    #aggration on transaction data and creating customer features.\n",
    "    agg_customer_data = transaction_info.groupby(customer_id).agg(purchase_count = (basket_id, 'count'),\n",
    "                                                    avarage_purchase_amount = (sales_value,'mean'),\n",
    "                                                    max_purchase_amount =(sales_value, 'max'),\n",
    "                                                    discount_purchase_count = (coupon_match, count_non_zero),\n",
    "                                                    total_unique_item_count = (product_id, 'nunique'),\n",
    "                                                    total_stores_visited = (store_id,'nunique')\n",
    "                                                    ).reset_index()\n",
    "    \n",
    "    featuresDF = agg_customer_data.merge(avg_customer_basket,on = customer_id,how='left')\n",
    "    \n",
    "    return featuresDF\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating feature dataframe and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def features_and_labels():\n",
    "    \"\"\"Proccessing for features and labels to be used in predictions.\n",
    "    Also applying standart scaling to features in case of usage in a classifier.\n",
    "    \"\"\"\n",
    "    \n",
    "    labelDF = labelling(transaction_data)\n",
    "    featureDF = data_proccessing_user(transaction_data,productDF,coupon_redemptDf)\n",
    "    train_test_df = featureDF.merge(labelDF, on=customer_id,how = 'inner').set_index(customer_id)\n",
    "    features = train_test_df.drop('label',axis=1)\n",
    "    sc = StandardScaler()\n",
    "    scaled_features = sc.fit_transform(features)\n",
    "    labels = train_test_df.label\n",
    "    \n",
    "    return features, scaled_features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "features, scaled_features,labels = features_and_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features dataframe preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_count</th>\n",
       "      <th>avarage_purchase_amount</th>\n",
       "      <th>max_purchase_amount</th>\n",
       "      <th>discount_purchase_count</th>\n",
       "      <th>total_unique_item_count</th>\n",
       "      <th>total_stores_visited</th>\n",
       "      <th>avg_basket_value</th>\n",
       "      <th>avg_distinct_items_basket</th>\n",
       "      <th>avg_items_in_basket</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>household_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1727</td>\n",
       "      <td>2.507331</td>\n",
       "      <td>12.50</td>\n",
       "      <td>72.0</td>\n",
       "      <td>677</td>\n",
       "      <td>2</td>\n",
       "      <td>2.783575</td>\n",
       "      <td>20.081395</td>\n",
       "      <td>20.081395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>714</td>\n",
       "      <td>2.737171</td>\n",
       "      <td>21.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546</td>\n",
       "      <td>5</td>\n",
       "      <td>3.258139</td>\n",
       "      <td>15.866667</td>\n",
       "      <td>15.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>922</td>\n",
       "      <td>2.877668</td>\n",
       "      <td>29.37</td>\n",
       "      <td>35.0</td>\n",
       "      <td>516</td>\n",
       "      <td>3</td>\n",
       "      <td>3.204537</td>\n",
       "      <td>19.617021</td>\n",
       "      <td>19.617021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>301</td>\n",
       "      <td>3.987076</td>\n",
       "      <td>37.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164</td>\n",
       "      <td>6</td>\n",
       "      <td>4.044173</td>\n",
       "      <td>10.033333</td>\n",
       "      <td>10.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>222</td>\n",
       "      <td>3.509279</td>\n",
       "      <td>21.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199</td>\n",
       "      <td>3</td>\n",
       "      <td>4.686616</td>\n",
       "      <td>5.550000</td>\n",
       "      <td>5.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>1489</td>\n",
       "      <td>2.914480</td>\n",
       "      <td>50.00</td>\n",
       "      <td>31.0</td>\n",
       "      <td>758</td>\n",
       "      <td>3</td>\n",
       "      <td>7.708217</td>\n",
       "      <td>23.634921</td>\n",
       "      <td>23.634921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>1962</td>\n",
       "      <td>3.624862</td>\n",
       "      <td>40.36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>991</td>\n",
       "      <td>12</td>\n",
       "      <td>4.371505</td>\n",
       "      <td>8.877828</td>\n",
       "      <td>8.877828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>859</td>\n",
       "      <td>3.028638</td>\n",
       "      <td>28.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>642</td>\n",
       "      <td>7</td>\n",
       "      <td>3.832739</td>\n",
       "      <td>4.994186</td>\n",
       "      <td>4.994186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>1166</td>\n",
       "      <td>2.910866</td>\n",
       "      <td>57.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>709</td>\n",
       "      <td>9</td>\n",
       "      <td>6.773943</td>\n",
       "      <td>12.955556</td>\n",
       "      <td>12.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>1503</td>\n",
       "      <td>3.650140</td>\n",
       "      <td>63.96</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1082</td>\n",
       "      <td>9</td>\n",
       "      <td>8.951766</td>\n",
       "      <td>13.300885</td>\n",
       "      <td>13.300885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               purchase_count  avarage_purchase_amount  max_purchase_amount  \\\n",
       "household_key                                                                 \n",
       "1                        1727                 2.507331                12.50   \n",
       "2                         714                 2.737171                21.99   \n",
       "3                         922                 2.877668                29.37   \n",
       "4                         301                 3.987076                37.34   \n",
       "5                         222                 3.509279                21.99   \n",
       "...                       ...                      ...                  ...   \n",
       "2496                     1489                 2.914480                50.00   \n",
       "2497                     1962                 3.624862                40.36   \n",
       "2498                      859                 3.028638                28.64   \n",
       "2499                     1166                 2.910866                57.00   \n",
       "2500                     1503                 3.650140                63.96   \n",
       "\n",
       "               discount_purchase_count  total_unique_item_count  \\\n",
       "household_key                                                     \n",
       "1                                 72.0                      677   \n",
       "2                                  0.0                      546   \n",
       "3                                 35.0                      516   \n",
       "4                                  0.0                      164   \n",
       "5                                  0.0                      199   \n",
       "...                                ...                      ...   \n",
       "2496                              31.0                      758   \n",
       "2497                               2.0                      991   \n",
       "2498                               0.0                      642   \n",
       "2499                               1.0                      709   \n",
       "2500                              40.0                     1082   \n",
       "\n",
       "               total_stores_visited  avg_basket_value  \\\n",
       "household_key                                           \n",
       "1                                 2          2.783575   \n",
       "2                                 5          3.258139   \n",
       "3                                 3          3.204537   \n",
       "4                                 6          4.044173   \n",
       "5                                 3          4.686616   \n",
       "...                             ...               ...   \n",
       "2496                              3          7.708217   \n",
       "2497                             12          4.371505   \n",
       "2498                              7          3.832739   \n",
       "2499                              9          6.773943   \n",
       "2500                              9          8.951766   \n",
       "\n",
       "               avg_distinct_items_basket  avg_items_in_basket  \n",
       "household_key                                                  \n",
       "1                              20.081395            20.081395  \n",
       "2                              15.866667            15.866667  \n",
       "3                              19.617021            19.617021  \n",
       "4                              10.033333            10.033333  \n",
       "5                               5.550000             5.550000  \n",
       "...                                  ...                  ...  \n",
       "2496                           23.634921            23.634921  \n",
       "2497                            8.877828             8.877828  \n",
       "2498                            4.994186             4.994186  \n",
       "2499                           12.955556            12.955556  \n",
       "2500                           13.300885            13.300885  \n",
       "\n",
       "[2500 rows x 9 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def splitting():\n",
    "    features,_,labels = features_and_labels()\n",
    "    \n",
    "    \n",
    "    #keep the labels ratio to not to get imbalanced training dataset.\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels,\n",
    "                                                    stratify=labels, \n",
    "                                                    test_size=0.3,random_state=92)\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test =splitting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing multilayer perceptron estimator and its parameters to be used in grid search to select best performed parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score,classification_report,confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def mlp_classifier():\n",
    "    \n",
    "    mlp = MLPClassifier()\n",
    "    \n",
    "    mlp_parameters = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['lbfgs', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "    'max_iter': [150,250,350]\n",
    "    }\n",
    "    \n",
    "    mlp_grid = GridSearchCV(mlp, mlp_parameters, n_jobs=-1, cv=4)\n",
    "    mlp_grid.fit(X_train, y_train)\n",
    "    print('Best parameters found for MLP Classifier : \\n', mlp_grid.best_params_)\n",
    "    \n",
    "    best_mlp_estimator = mlp_grid.best_estimator_\n",
    "    y_pred_mlp = best_mlp_estimator.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred_mlp))\n",
    "\n",
    "    mlp_f1_score = f1_score(y_test, y_pred_mlp, average=\"macro\")\n",
    "    \n",
    "    return y_pred_mlp, mlp_f1_score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing random forest estimator and its parameters to be used in grid search to select best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def random_forest_classifier():\n",
    "    \n",
    "    rf = RandomForestClassifier()\n",
    "\n",
    "    rf_parameters = {\n",
    "            \"n_estimators\" : [10,50,150,200],\n",
    "            \"max_features\" : [\"auto\", \"log2\", \"sqrt\"],\n",
    "            \"bootstrap\"    : [True, False],\n",
    "            \"min_samples_leaf\": [1,2,3]\n",
    "                    }\n",
    "    \n",
    "    rf_grid = GridSearchCV(rf, rf_parameters, n_jobs=-1, cv=3)\n",
    "    rf_grid.fit(X_train, y_train)\n",
    "    print('Best Random Forest estimator parameters found:\\n', rf_grid.best_params_)\n",
    "    \n",
    "    best_rf_estimator = rf_grid.best_estimator_\n",
    "    y_pred_rf = best_rf_estimator.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred_rf))\n",
    "    \n",
    "    rf_f1_score = f1_score(y_test, y_pred_rf, average=\"macro\")\n",
    "    \n",
    "    return y_pred_rf, rf_f1_score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### and also gradient boosted tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def gradient_boosting_tree():\n",
    "    \n",
    "    gbt = GradientBoostingClassifier()\n",
    "    \n",
    "    gbt_parameters = {\n",
    "            \"loss\":[\"deviance\"],\n",
    "            \"learning_rate\": [0.01, 0.05, 0.1, 0.2],\n",
    "            \"min_samples_split\": [2,4,6],\n",
    "            \"min_samples_leaf\": [1,3,5],\n",
    "            \"max_depth\":[3,5,10],\n",
    "            \"criterion\": [\"friedman_mse\"],\n",
    "            \"n_estimators\":[50,100,200]\n",
    "                }\n",
    "    \n",
    "    gbt_grid = GridSearchCV(gbt, gbt_parameters, n_jobs=-1, cv=4)\n",
    "    gbt_grid.fit(X_train, y_train)\n",
    "    print('Best Gradient boosted tree estimator parameters found:\\n', gbt_grid.best_params_)\n",
    "    \n",
    "    best_gbt_estimator = gbt_grid.best_estimator_\n",
    "    y_pred_gbt = best_gbt_estimator.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred_gbt))\n",
    "    \n",
    "    gbt_f1_score = f1_score(y_test, y_pred_gbt, average=\"macro\")\n",
    "    \n",
    "    return y_pred_gbt, gbt_f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results of those 3 alghorithms on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found for MLP Classifier : \n",
      " {'activation': 'tanh', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'adaptive', 'max_iter': 350, 'solver': 'adam'}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.93      0.73       445\n",
      "           1       0.42      0.07      0.12       305\n",
      "\n",
      "    accuracy                           0.58       750\n",
      "   macro avg       0.51      0.50      0.42       750\n",
      "weighted avg       0.52      0.58      0.48       750\n",
      "\n",
      "Best Random Forest estimator parameters found:\n",
      " {'bootstrap': True, 'max_features': 'auto', 'min_samples_leaf': 3, 'n_estimators': 10}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.71      0.65       445\n",
      "           1       0.42      0.30      0.35       305\n",
      "\n",
      "    accuracy                           0.55       750\n",
      "   macro avg       0.51      0.51      0.50       750\n",
      "weighted avg       0.53      0.55      0.53       750\n",
      "\n",
      "Best Gradient boosted tree estimator parameters found:\n",
      " {'criterion': 'friedman_mse', 'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.97      0.74       445\n",
      "           1       0.55      0.06      0.10       305\n",
      "\n",
      "    accuracy                           0.60       750\n",
      "   macro avg       0.57      0.51      0.42       750\n",
      "weighted avg       0.58      0.60      0.48       750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_mlp, mlp_f1_score = mlp_classifier()\n",
    "y_pred_rf, rf_f1_score = random_forest_classifier()\n",
    "y_pred_gbt, gbt_f1_score = gradient_boosting_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the algorithm who has highest f1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_predictions(y_pred_rf,y_pred_mlp,y_pred_gbt):\n",
    "    if (rf_f1_score > mlp_f1_score and\n",
    "        rf_f1_score > gbt_f1_score):\n",
    "        #Return random forest prediction\n",
    "        print(\"Random Forest model predictions was selected with \" + str(rf_f1_score) + \"f1 score\")\n",
    "        return y_pred_rf\n",
    "    elif (mlp_f1_score > rf_f1_score and\n",
    "          mlp_f1_score > gbt_f1_score):\n",
    "        #Return multilayer perceptron predictions\n",
    "        print(\"Multilayer Perceptron model predictions was selected with \" + str(mlp_f1_score) + \"f1 score\")\n",
    "        return y_pred_mlp\n",
    "    elif (gbt_f1_score > rf_f1_score and\n",
    "          gbt_f1_score > mlp_f1_score):\n",
    "        #Return multilayer perceptron predictions\n",
    "        print(\"Gradient Boosting Tree model predictions was selected with \" + str(gbt_f1_score) + \"f1 score\")\n",
    "        return y_pred_gbt\n",
    "    else:\n",
    "        print(\"No model was found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt     \n",
    "def plot_confusion_matrix():\n",
    "    \n",
    "    best_model_pred= load_best_predictions(y_pred_rf,y_pred_mlp,y_pred_gbt)\n",
    "    labels= [0,1]\n",
    "    cm = confusion_matrix(y_test,best_model_pred,labels)\n",
    "    ax= plt.subplot()\n",
    "    sns.heatmap(cm, annot=True,fmt='g', ax = ax); #annot=True to annotate cells\n",
    "\n",
    "    # labels, title and ticks\n",
    "    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "    ax.set_title('Confusion Matrix'); \n",
    "    ax.xaxis.set_ticklabels(['not churn', 'churn']); ax.yaxis.set_ticklabels(['not churn', 'churn'])\n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom + 0.5, top - 0.5)\n",
    "    print('accuracy = ' + str(accuracy_score(y_test, best_model_pred)))\n",
    "    print('f1 score = ' + str(f1_score(y_test, best_model_pred, average=\"macro\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As it seems there is a lot of room to grow on the quality. This might be overcome with more feature engineering and including customer demographic data. However if we can in predict nearly %33 percent of customer who will churn, it will still have a positive impact on our campaigns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model predictions was selected with 0.5032967032967033f1 score\n",
      "accuracy = 0.548\n",
      "f1 score = 0.5032967032967033\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
